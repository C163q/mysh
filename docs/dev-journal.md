# 开发笔记

记录开发过程、思路等。

## 内建命令

一个最简单的Shell在处理命令时，无非就是3情况：

- 内建命令
- 外部可执行程序
- 无法访问

在处理内建命令时，我的第一个想法就是设置一个注册表，一般来说是一个哈希表，键为命令名，值为调用的函数。
这样子就可以方便的集中管理。

内建命令既然是固定的，在编译时就确定了，自然就会想到可以把这张表作为一个`const`的全局变量。然而可惜的是，
在目前版本的rust中，无论是`BTreeMap`还是`HashMap`，都不是`const`的。准确来说，我需要用到`new`和`insert`
方法，但前者只有`new`是`const`的，而后者都不是`const`的。

这就很难受，因为`static`声明周期的变量必须是能够`const`初始化的，使用`OnceLock`就太过了，Shell程序毕竟
还是单线程的程序，因此使用`thread_local`就可以了。

这样，整个命令的处理逻辑就非常清晰了。首先查表，如果找到命令，调用键值存储的函数，没有找到，尝试调用作为
外部程序路径运行，如果找不到，则表示无法找到命令。

## 在PATH中查找可执行文件

无论是`execv`还是`Command::new`，都会自动帮助寻找`PATH`当中的可执行文件，但是内建命令`type`就不一样了，
我们必须自己实现查找的逻辑。

最初的实现逻辑嵌套非常深，非常不优雅，好在的是rust的`clippy`足够强大，在不少地方都表示可以简化，比如：

```rust
if let Some(v) = value {
    if u.condition() {}
}
// ^^^ old / new vvv
if let Some(v) = value && u.condition() {}
```

其实最最重要的改动还是使用了迭代器的`flatten()`方法。rust的`Option`和`Result`可以转换为迭代器，并且只在
`Some(_)`和`Ok(_)`的时候产出一个元素的技巧实在太好用了，配合`flatten`，可以很方便的处理迭代目录中的文件时，
返回的`Result`。

总之，在反复的优化之后，代码变成如下的样子：

```rust
fn get_executable_in_path(cmd: &str, env: &ExecEnv) -> Option<DirEntry> {
    fn dir_get_executable(name: &str, reader: ReadDir) -> Option<DirEntry> {
        reader
            .flatten()
            .find(|entry| entry.path().is_executable() && entry.file_name() == name)
    }

    for dir in env.path_env.iter() {
        if let Ok(entries) = read_dir(dir)
            && let Some(entry) = dir_get_executable(cmd, entries)
        {
            return Some(entry);
        }
    }

    None
}
```

优雅。

## 重定向

我没有去查其他的Shell是如何实现重定向的，我的方法是交换两个文件的文件描述符。既然使用的是这种方法，那么
自然就不支持`Windows`系统了。

比如我有这样的重定向的要求：`3> file`。依照交换文件描述符的方法，首先打开`file`文件，得到其文件描述符(`new_fd`)，
然后使用`dup`复制`fd == 3`(`old_fd`)的文件`tmp_fd`，然后使用`dup2`使用`new_fd`覆盖`old_fd`，然后使用`tmp_fd`
覆盖`new_fd`，最后关闭`tmp_fd`（因为此时`tmp_fd`和`new_fd`都指向原本`fd == 3`的文件）。

在启动进程之后，换回去，其实就是将`new_fd`覆盖`old_fd`，然后关闭`new_fd`。

上面这种方法其实可以通过`RAII`来实现，进程启动前换`fd`的操作由对象的构造函数处理，启动之后换回的操作使用
对象的析构函数处理。

在看了S081课程之后，我觉得执行外部程序部分的逻辑应该写成先`fork`，然后再设置重定向和管道，然后再使用`execvp`。
这里有几个需要注意的地方，由于我们需要等待`execvp`是否真的调用成功，并且不等待程序执行完成，所以我们不能使用
`wait`，而且由于使用了`fork`，所以两者之间属于不同的进程了，需要用一些IPC的功能来交流。我这边搜集到的是使用
管道来完成，给管道设置`FD_CLOEXEC`标志，让它在调用`execvp`成功后关闭管道，然后在父进程中就会读到0字节的数据，
就知道进程创建成功了。如果失败了，就向管道写一些东西再关闭管道。

不过我发现`Command`提供`pre_exec`方法，允许设置`execvp`前且`fork`后的时间段做的处理。这样子就可以在`pre_exec`
的闭包中完成重定向和管道了。但缺点是无法辨别运行失败到底是闭包导致的还是`execvp`导致的，原因是闭包中返回的
`Error`和`execvp`返回的`Error`整合的一起了，并且会在整合后，也就是`do_exec`调用完之后，重新提取`Error`的
`raw_os_error`，然后通过管道传递。也就是说，父进程无法得到错误号以外的任何信息。我也无法通过全局变量共享的
方法处理，毕竟是两个不同的进程，内存空间是隔离的，除非使用IPC。

## 命令解析

命令解析是这里面写的最最头疼的部分，最主要的原因是由相当多的`edge case`。比如`echo "value" >1.txt`该怎么处理？
`echo 'va'lu"e"   >>> 1.txt`该怎么处理？等等……

我暂时不想在此处讲太多，因为这只是多种特殊情况的堆砌而已。

## 集成测试

我发现rust的测试好像是会截获`println!`的输出的，我在`cargo test`中如法炮制，交换fd，想要捕获指令输出到
标准输出的结果，结果发现不行……

在查了`println!`的实现后发现，它会调用`stdio::print_to`函数，这个函数内部会使用`print_to_buffer_if_capture_used`
函数，它会将内容捕获，而不输出。

要么解决方法之一是使用`cargo run -- --nocapture`。但是……我觉得还是应该重写一下输出部分，防止捕获。
于是我就把所有的`println!`全部改成了`write!`宏了。

还有就是，在集成测试的时候，会出现`cargo test`的输出混入重定向文件中的情况，结果就是导致测试失败。这应该是因为
`cargo test`是多线程同时测试的，这就导致前面两个测试会一起进行，这往往导致重定向的文件的内容是混乱的，甚至往往
会包括`cargo test`本身的提示信息。

没办法，重定向本身就是以进程为单位的，对于多线程来说，这个问题不好解决。现在我能想到的办法就是阻塞线程，给
需要标准输出重定向的测试函数中给标准输出加锁。

## 自动补全

自动补全方面，我使用的是`rustyline`库。这个库目前不是非常完善，但是足够用。为了实现自动补全，我得要重写解析参数的
逻辑。原本解析参数是一个函数全部完成的，现在必须拆成两个函数，先将一行解析为多个片段，这样补全时就以片段为单位了。
然后将片段解析为命令。命令与片段之间的区别就是会考虑重定向符之类的东西，并且不将它视为命令的一部分，而片段则
一视同仁。

`rustyline`的引入首先就是让命令输入的手感变好了，也就是支持左右方向键等操作。而这些只需要实例化一个`Editor`类型
就可以了，非常方便。但是添加自动补全功能依旧很麻烦，`Completer`仅仅是一个`trait`，而内置的`Completer`也就只有
一个`FilenameCompleter`而已，这肯定是远远不够的。

## 管道

管道符的加入意味着指令执行函数必须要重构了。之前的版本仅仅是针对一个命令执行的，而现在需要同时执行多条命令。

管道符本身的解析并不难，至少没有重定向的解析那么困难。问题就在于如何同时运行多个程序，并使用管道符串接起来。
如果全部是外部命令，做到这一点其实并不难，但重点是有内部命令，目前的处理方式中，所有的内部命令都是调用函数的形式，
这意味着除非引入多线程，否则不能够做到发起执行的计划，然后转而处理下一个命令，等到发出所有命令之后，依次等待。
目前就只为外部命令实现并行执行，而为内部命令实现依序执行的方式，后续再尝试引入多线程。

我在查看了`zsh`之后，我发现，`zsh`在执行内部命令时，应该是对某些特定的内部命令使用`fork`的方式来处理的。这样做
就可以把内部命令转换为外部命令。
